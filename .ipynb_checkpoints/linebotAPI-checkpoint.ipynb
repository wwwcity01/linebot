{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29351d57-f91a-4df0-b935-208daa2a26a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import logging\n",
    "import subprocess\n",
    "import tempfile\n",
    "import whisper\n",
    "import requests\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from flask import Flask, request, abort, jsonify, send_file\n",
    "from linebot import LineBotApi, WebhookHandler\n",
    "from linebot.exceptions import InvalidSignatureError\n",
    "from linebot.models import MessageEvent, AudioMessage, TextMessage, TextSendMessage, AudioSendMessage\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "import opencc\n",
    "app = Flask(__name__)\n",
    "app.secret_key = os.urandom(24)\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "# LINE bot 設置\n",
    "LINE_CHANNEL_ACCESS_TOKEN = 'OG/Z9nCIEAvPSMNHsdfcOXS3ulWyNQihSszijTJdXEfa7srZYeuTKpUkarrwf6TXcEOwjp/6EH+0l/aceCyrQWU9KUnRlFvdl47EFT8P+0GiMvKwa03TJbAy9c7sUk/Z8l50wjUNz5n/LOXtDAcK/QdB04t89/1O/w1cDnyilFU='\n",
    "LINE_CHANNEL_SECRET = 'f64b31faefee2d64598ff9c317f8ce43'\n",
    "SERVER_URL = 'https://linebot-smq6.onrender.com'\n",
    "STT_API_URL = 'http://180.218.16.187:30303/recognition_long_audio'\n",
    "TTS_API_URL = 'http://180.218.16.187:30303/getTTSfromText'\n",
    "LLM_API_URL = 'http://61.66.218.215:30315/llm_chat'\n",
    "SERVER_PORT = 8080\n",
    "line_bot_api = LineBotApi(LINE_CHANNEL_ACCESS_TOKEN)\n",
    "line_handler = WebhookHandler(LINE_CHANNEL_SECRET)\n",
    "# Whisper 和 LLM 模型設置\n",
    "stt_model = whisper.load_model(\"tiny\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"niwz/Mini-Chinese-Phi3\")\n",
    "llm_model = AutoModelForCausalLM.from_pretrained(\"niwz/Mini-Chinese-Phi3\").to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "converter = opencc.OpenCC('s2t')\n",
    "# 模型功能\n",
    "def get_text_from_audio(audio_path):\n",
    "    with open(audio_path, 'rb') as f:\n",
    "        files = {'audio': (os.path.basename(audio_path), f, 'audio/mpeg')}\n",
    "        response = requests.post(STT_API_URL, files=files)\n",
    "        return response.json().get('result', '無法辨識音訊') if response.status_code == 200 else '錄音語音品質不佳，請再試試。'\n",
    "def get_response_from_llm(query):\n",
    "    payload = {'token': 'TEST', 'query': query, 'prompt_name': '艾妮機器人', 'max_tokens': '256'}\n",
    "    response = requests.post(LLM_API_URL, data=payload)\n",
    "    return response.json().get('result', '無法獲取回應')\n",
    "def get_audio_from_text(text):\n",
    "    payload = {'tone': '0', 'speed': '0', 'content': text, 'gender': '1'}\n",
    "    response = requests.post(TTS_API_URL, data=payload)\n",
    "    audio_path = f'static/{int(time.time())}.mp3'\n",
    "    with open(audio_path, 'wb') as f:\n",
    "        f.write(response.content)\n",
    "    return audio_path\n",
    "def run_command(command):\n",
    "    try:\n",
    "        result = subprocess.run(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, encoding=\"utf-8\", timeout=3600)\n",
    "        return result.returncode == 0, result.stdout if result.returncode == 0 else result.stderr\n",
    "    except Exception as e:\n",
    "        return False, str(e)\n",
    "# 路由和處理函數\n",
    "@app.route(\"/\", methods=[\"GET\"])\n",
    "def home():\n",
    "    return \"Line Bot 已啟動並運作\"\n",
    "@app.route(\"/webhook\", methods=[\"POST\"])\n",
    "def callback():\n",
    "    signature = request.headers[\"X-Line-Signature\"]\n",
    "    body = request.get_data(as_text=True)\n",
    "    try:\n",
    "        line_handler.handle(body, signature)\n",
    "    except InvalidSignatureError:\n",
    "        abort(400)\n",
    "    return \"OK\"\n",
    "@app.route(\"/qa\", methods=[\"POST\"])\n",
    "def qa():\n",
    "    question = request.json.get('text')\n",
    "    if not question:\n",
    "        return jsonify({\"error\": \"未提供文本\"}), 400\n",
    "    answer = answer_question(question)\n",
    "    return jsonify({\"answer\": answer})\n",
    "@app.route(\"/transcribe\", methods=[\"POST\"])\n",
    "def transcribe():\n",
    "    audio_file = request.files.get('file')\n",
    "    if not audio_file:\n",
    "        return jsonify({\"error\": \"未上傳音訊檔案\"}), 400\n",
    "    with tempfile.NamedTemporaryFile(delete=False) as temp_audio_file:\n",
    "        audio_file.save(temp_audio_file.name)\n",
    "        audio = whisper.load_audio(temp_audio_file.name)\n",
    "        result = stt_model.transcribe(audio, language='zh')\n",
    "    os.remove(temp_audio_file.name)\n",
    "    return jsonify({\"transcription\": result['text']})\n",
    "@app.route('/synthesize', methods=['POST'])\n",
    "def synthesize():\n",
    "    content = request.form.get('content', '上傳資料內容有誤')\n",
    "    gender = request.form.get('gender', '1')\n",
    "    tone = request.form.get('tone', '0')\n",
    "    speed = request.form.get('speed', '0')\n",
    "    voices = {'1': \"zh-TW-YunJheNeural\", '0': \"zh-TW-HsiaoYuNeural\"}\n",
    "    voice = voices.get(gender, \"zh-TW-HsiaoChenNeural\")\n",
    "    pitch = f\"{tone}Hz\"\n",
    "    rate = f\"{speed}%\"\n",
    "    \n",
    "    output_path = f\"static/{int(time.time() * 1000)}.mp3\"\n",
    "    command = f'edge-tts --text \"{content}\" --write-media \"{output_path}\" --voice \"{voice}\" --pitch=\"{pitch}\" --rate=\"{rate}\"'\n",
    "    success, message = run_command(command)\n",
    "    if success:\n",
    "        return send_file(output_path, mimetype='audio/mpeg')\n",
    "    return jsonify({\"error\": message}), 500\n",
    "# 問答功能\n",
    "def answer_question(question):\n",
    "    inputs = tokenizer(question, return_tensors=\"pt\", padding=True).to(llm_model.device)\n",
    "    outputs = llm_model.generate(inputs['input_ids'], attention_mask=inputs['attention_mask'], max_new_tokens=256, pad_token_id=tokenizer.eos_token_id)\n",
    "    answer = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return converter.convert(answer)\n",
    "# Line handlers\n",
    "@line_handler.add(MessageEvent, message=AudioMessage)\n",
    "def handle_audio_message(event):\n",
    "    audio_path = f'static/{int(time.time())}.mp3'\n",
    "    with open(audio_path, 'wb') as fd:\n",
    "        for chunk in line_bot_api.get_message_content(event.message.id).iter_content():\n",
    "            fd.write(chunk)\n",
    "    text = get_text_from_audio(audio_path)\n",
    "    llm_response = get_response_from_llm(text)\n",
    "    reply_audio_path = get_audio_from_text(llm_response)\n",
    "    if os.path.exists(reply_audio_path):\n",
    "        line_bot_api.reply_message(\n",
    "            event.reply_token,\n",
    "            [\n",
    "                TextSendMessage(text=llm_response),\n",
    "                AudioSendMessage(original_content_url=f'{SERVER_URL}/{reply_audio_path}', duration=330)\n",
    "            ]\n",
    "        )\n",
    "    else:\n",
    "        line_bot_api.reply_message(event.reply_token, TextSendMessage(text=\"合成語音時錯誤，請檢查 TTS Server\"))\n",
    "@line_handler.add(MessageEvent, message=TextMessage)\n",
    "def handle_text_message(event):\n",
    "    text = event.message.text\n",
    "    llm_response = get_response_from_llm(text)\n",
    "    reply_audio_path = get_audio_from_text(llm_response)\n",
    "    if os.path.exists(reply_audio_path):\n",
    "        line_bot_api.reply_message(\n",
    "            event.reply_token,\n",
    "            [\n",
    "                TextSendMessage(text=llm_response),\n",
    "                AudioSendMessage(original_content_url=f'{SERVER_URL}/{reply_audio_path}', duration=330)\n",
    "            ]\n",
    "        )\n",
    "    else:\n",
    "        line_bot_api.reply_message(event.reply_token, TextSendMessage(text=\"合成語音時錯誤，請檢查 TTS Server\"))\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(debug=True, host=\"0.0.0.0\", port=SERVER_PORT, use_reloader=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227babf4-0b7c-4453-b91c-aa701a1fa1c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53925eb1-83db-41be-92a8-dcfc73796848",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import logging\n",
    "import subprocess\n",
    "import tempfile\n",
    "import whisper\n",
    "import requests\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from flask import Flask, request, abort, jsonify, send_file\n",
    "from linebot import LineBotApi, WebhookHandler\n",
    "from linebot.exceptions import InvalidSignatureError\n",
    "from linebot.models import MessageEvent, AudioMessage, TextMessage, TextSendMessage, AudioSendMessage\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "import opencc\n",
    "app = Flask(__name__)\n",
    "app.secret_key = os.urandom(24)\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "# LINE bot 設置\n",
    "LINE_CHANNEL_ACCESS_TOKEN = 'OG/Z9nCIEAvPSMNHsdfcOXS3ulWyNQihSszijTJdXEfa7srZYeuTKpUkarrwf6TXcEOwjp/6EH+0l/aceCyrQWU9KUnRlFvdl47EFT8P+0GiMvKwa03TJbAy9c7sUk/Z8l50wjUNz5n/LOXtDAcK/QdB04t89/1O/w1cDnyilFU='\n",
    "LINE_CHANNEL_SECRET = 'f64b31faefee2d64598ff9c317f8ce43'\n",
    "SERVER_URL = 'https://linebot-smq6.onrender.com'\n",
    "STT_API_URL = 'http://180.218.16.187:30303/recognition_long_audio'\n",
    "TTS_API_URL = 'http://180.218.16.187:30303/getTTSfromText'\n",
    "LLM_API_URL = 'http://61.66.218.215:30315/llm_chat'\n",
    "SERVER_PORT = 8080\n",
    "line_bot_api = LineBotApi(LINE_CHANNEL_ACCESS_TOKEN)\n",
    "line_handler = WebhookHandler(LINE_CHANNEL_SECRET)\n",
    "# Whisper 和 LLM 模型設置\n",
    "stt_model = whisper.load_model(\"tiny\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"niwz/Mini-Chinese-Phi3\")\n",
    "llm_model = AutoModelForCausalLM.from_pretrained(\"niwz/Mini-Chinese-Phi3\").to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "converter = opencc.OpenCC('s2t')\n",
    "# 模型功能\n",
    "def get_text_from_audio(audio_path):\n",
    "    with open(audio_path, 'rb') as f:\n",
    "        files = {'audio': (os.path.basename(audio_path), f, 'audio/mpeg')}\n",
    "        response = requests.post(STT_API_URL, files=files)\n",
    "        return response.json().get('result', '無法辨識音訊') if response.status_code == 200 else '錄音語音品質不佳，請再試試。'\n",
    "def get_response_from_llm(query):\n",
    "    payload = {'token': 'TEST', 'query': query, 'prompt_name': '艾妮機器人', 'max_tokens': '256'}\n",
    "    response = requests.post(LLM_API_URL, data=payload)\n",
    "    return response.json().get('result', '無法獲取回應')\n",
    "def get_audio_from_text(text):\n",
    "    payload = {'tone': '0', 'speed': '0', 'content': text, 'gender': '1'}\n",
    "    response = requests.post(TTS_API_URL, data=payload)\n",
    "    audio_path = f'static/{int(time.time())}.mp3'\n",
    "    with open(audio_path, 'wb') as f:\n",
    "        f.write(response.content)\n",
    "    return audio_path\n",
    "def run_command(command):\n",
    "    try:\n",
    "        result = subprocess.run(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, encoding=\"utf-8\", timeout=3600)\n",
    "        return result.returncode == 0, result.stdout if result.returncode == 0 else result.stderr\n",
    "    except Exception as e:\n",
    "        return False, str(e)\n",
    "# 路由和處理函數\n",
    "@app.route(\"/\", methods=[\"GET\"])\n",
    "def home():\n",
    "    return \"Line Bot 已啟動並運作\"\n",
    "@app.route(\"/webhook\", methods=[\"POST\"])\n",
    "def callback():\n",
    "    signature = request.headers[\"X-Line-Signature\"]\n",
    "    body = request.get_data(as_text=True)\n",
    "    try:\n",
    "        line_handler.handle(body, signature)\n",
    "    except InvalidSignatureError:\n",
    "        abort(400)\n",
    "    return \"OK\"\n",
    "@app.route(\"/qa\", methods=[\"POST\"])\n",
    "def qa():\n",
    "    question = request.json.get('text')\n",
    "    if not question:\n",
    "        return jsonify({\"error\": \"未提供文本\"}), 400\n",
    "    answer = answer_question(question)\n",
    "    return jsonify({\"answer\": answer})\n",
    "@app.route(\"/transcribe\", methods=[\"POST\"])\n",
    "def transcribe():\n",
    "    audio_file = request.files.get('file')\n",
    "    if not audio_file:\n",
    "        return jsonify({\"error\": \"未上傳音訊檔案\"}), 400\n",
    "    with tempfile.NamedTemporaryFile(delete=False) as temp_audio_file:\n",
    "        audio_file.save(temp_audio_file.name)\n",
    "        audio = whisper.load_audio(temp_audio_file.name)\n",
    "        result = stt_model.transcribe(audio, language='zh')\n",
    "    os.remove(temp_audio_file.name)\n",
    "    return jsonify({\"transcription\": result['text']})\n",
    "@app.route('/synthesize', methods=['POST'])\n",
    "def synthesize():\n",
    "    content = request.form.get('content', '上傳資料內容有誤')\n",
    "    gender = request.form.get('gender', '1')\n",
    "    tone = request.form.get('tone', '0')\n",
    "    speed = request.form.get('speed', '0')\n",
    "    voices = {'1': \"zh-TW-YunJheNeural\", '0': \"zh-TW-HsiaoYuNeural\"}\n",
    "    voice = voices.get(gender, \"zh-TW-HsiaoChenNeural\")\n",
    "    pitch = f\"{tone}Hz\"\n",
    "    rate = f\"{speed}%\"\n",
    "    \n",
    "    output_path = f\"static/{int(time.time() * 1000)}.mp3\"\n",
    "    command = f'edge-tts --text \"{content}\" --write-media \"{output_path}\" --voice \"{voice}\" --pitch=\"{pitch}\" --rate=\"{rate}\"'\n",
    "    success, message = run_command(command)\n",
    "    if success:\n",
    "        return send_file(output_path, mimetype='audio/mpeg')\n",
    "    return jsonify({\"error\": message}), 500\n",
    "# 問答功能\n",
    "def answer_question(question):\n",
    "    inputs = tokenizer(question, return_tensors=\"pt\", padding=True).to(llm_model.device)\n",
    "    outputs = llm_model.generate(inputs['input_ids'], attention_mask=inputs['attention_mask'], max_new_tokens=256, pad_token_id=tokenizer.eos_token_id)\n",
    "    answer = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return converter.convert(answer)\n",
    "# Line handlers\n",
    "@line_handler.add(MessageEvent, message=AudioMessage)\n",
    "def handle_audio_message(event):\n",
    "    audio_path = f'static/{int(time.time())}.mp3'\n",
    "    with open(audio_path, 'wb') as fd:\n",
    "        for chunk in line_bot_api.get_message_content(event.message.id).iter_content():\n",
    "            fd.write(chunk)\n",
    "    text = get_text_from_audio(audio_path)\n",
    "    llm_response = get_response_from_llm(text)\n",
    "    reply_audio_path = get_audio_from_text(llm_response)\n",
    "    if os.path.exists(reply_audio_path):\n",
    "        line_bot_api.reply_message(\n",
    "            event.reply_token,\n",
    "            [\n",
    "                TextSendMessage(text=llm_response),\n",
    "                AudioSendMessage(original_content_url=f'{SERVER_URL}/{reply_audio_path}', duration=330)\n",
    "            ]\n",
    "        )\n",
    "    else:\n",
    "        line_bot_api.reply_message(event.reply_token, TextSendMessage(text=\"合成語音時錯誤，請檢查 TTS Server\"))\n",
    "@line_handler.add(MessageEvent, message=TextMessage)\n",
    "def handle_text_message(event):\n",
    "    text = event.message.text\n",
    "    llm_response = get_response_from_llm(text)\n",
    "    reply_audio_path = get_audio_from_text(llm_response)\n",
    "    if os.path.exists(reply_audio_path):\n",
    "        line_bot_api.reply_message(\n",
    "            event.reply_token,\n",
    "            [\n",
    "                TextSendMessage(text=llm_response),\n",
    "                AudioSendMessage(original_content_url=f'{SERVER_URL}/{reply_audio_path}', duration=330)\n",
    "            ]\n",
    "        )\n",
    "    else:\n",
    "        line_bot_api.reply_message(event.reply_token, TextSendMessage(text=\"合成語音時錯誤，請檢查 TTS Server\"))\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(debug=True, host=\"0.0.0.0\", port=SERVER_PORT, use_reloader=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd8ff2d-1c1d-4cc5-92f5-75978fdac578",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import logging\n",
    "import subprocess\n",
    "import tempfile\n",
    "import whisper\n",
    "import requests\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from flask import Flask, request, abort, jsonify, send_file\n",
    "from linebot import LineBotApi, WebhookHandler\n",
    "from linebot.exceptions import InvalidSignatureError\n",
    "from linebot.models import MessageEvent, AudioMessage, TextMessage, TextSendMessage, AudioSendMessage\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "import opencc\n",
    "app = Flask(__name__)\n",
    "app.secret_key = os.urandom(24)\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "# LINE bot 設置\n",
    "LINE_CHANNEL_ACCESS_TOKEN = 'OG/Z9nCIEAvPSMNHsdfcOXS3ulWyNQihSszijTJdXEfa7srZYeuTKpUkarrwf6TXcEOwjp/6EH+0l/aceCyrQWU9KUnRlFvdl47EFT8P+0GiMvKwa03TJbAy9c7sUk/Z8l50wjUNz5n/LOXtDAcK/QdB04t89/1O/w1cDnyilFU='\n",
    "LINE_CHANNEL_SECRET = 'f64b31faefee2d64598ff9c317f8ce43'\n",
    "SERVER_URL = 'https://linebot-smq6.onrender.com'\n",
    "STT_API_URL = 'http://180.218.16.187:30303/recognition_long_audio'\n",
    "TTS_API_URL = 'http://180.218.16.187:30303/getTTSfromText'\n",
    "LLM_API_URL = 'http://61.66.218.215:30315/llm_chat'\n",
    "SERVER_PORT = 8080\n",
    "line_bot_api = LineBotApi(LINE_CHANNEL_ACCESS_TOKEN)\n",
    "line_handler = WebhookHandler(LINE_CHANNEL_SECRET)\n",
    "# Whisper 和 LLM 模型設置\n",
    "stt_model = whisper.load_model(\"tiny\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"niwz/Mini-Chinese-Phi3\")\n",
    "llm_model = AutoModelForCausalLM.from_pretrained(\"niwz/Mini-Chinese-Phi3\").to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "converter = opencc.OpenCC('s2t')\n",
    "# 模型功能\n",
    "def get_text_from_audio(audio_path):\n",
    "    with open(audio_path, 'rb') as f:\n",
    "        files = {'audio': (os.path.basename(audio_path), f, 'audio/mpeg')}\n",
    "        response = requests.post(STT_API_URL, files=files)\n",
    "        return response.json().get('result', '無法辨識音訊') if response.status_code == 200 else '錄音語音品質不佳，請再試試。'\n",
    "def get_response_from_llm(query):\n",
    "    payload = {'token': 'TEST', 'query': query, 'prompt_name': '艾妮機器人', 'max_tokens': '256'}\n",
    "    response = requests.post(LLM_API_URL, data=payload)\n",
    "    return response.json().get('result', '無法獲取回應')\n",
    "def get_audio_from_text(text):\n",
    "    payload = {'tone': '0', 'speed': '0', 'content': text, 'gender': '1'}\n",
    "    response = requests.post(TTS_API_URL, data=payload)\n",
    "    audio_path = f'static/{int(time.time())}.mp3'\n",
    "    with open(audio_path, 'wb') as f:\n",
    "        f.write(response.content)\n",
    "    return audio_path\n",
    "def run_command(command):\n",
    "    try:\n",
    "        result = subprocess.run(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, encoding=\"utf-8\", timeout=3600)\n",
    "        return result.returncode == 0, result.stdout if result.returncode == 0 else result.stderr\n",
    "    except Exception as e:\n",
    "        return False, str(e)\n",
    "# 路由和處理函數\n",
    "@app.route(\"/\", methods=[\"GET\"])\n",
    "def home():\n",
    "    return \"Line Bot 已啟動並運作\"\n",
    "@app.route(\"/webhook\", methods=[\"POST\"])\n",
    "def callback():\n",
    "    signature = request.headers[\"X-Line-Signature\"]\n",
    "    body = request.get_data(as_text=True)\n",
    "    try:\n",
    "        line_handler.handle(body, signature)\n",
    "    except InvalidSignatureError:\n",
    "        abort(400)\n",
    "    return \"OK\"\n",
    "@app.route(\"/qa\", methods=[\"POST\"])\n",
    "def qa():\n",
    "    question = request.json.get('text')\n",
    "    if not question:\n",
    "        return jsonify({\"error\": \"未提供文本\"}), 400\n",
    "    answer = answer_question(question)\n",
    "    return jsonify({\"answer\": answer})\n",
    "@app.route(\"/transcribe\", methods=[\"POST\"])\n",
    "def transcribe():\n",
    "    audio_file = request.files.get('file')\n",
    "    if not audio_file:\n",
    "        return jsonify({\"error\": \"未上傳音訊檔案\"}), 400\n",
    "    with tempfile.NamedTemporaryFile(delete=False) as temp_audio_file:\n",
    "        audio_file.save(temp_audio_file.name)\n",
    "        audio = whisper.load_audio(temp_audio_file.name)\n",
    "        result = stt_model.transcribe(audio, language='zh')\n",
    "    os.remove(temp_audio_file.name)\n",
    "    return jsonify({\"transcription\": result['text']})\n",
    "@app.route('/synthesize', methods=['POST'])\n",
    "def synthesize():\n",
    "    content = request.form.get('content', '上傳資料內容有誤')\n",
    "    gender = request.form.get('gender', '1')\n",
    "    tone = request.form.get('tone', '0')\n",
    "    speed = request.form.get('speed', '0')\n",
    "    voices = {'1': \"zh-TW-YunJheNeural\", '0': \"zh-TW-HsiaoYuNeural\"}\n",
    "    voice = voices.get(gender, \"zh-TW-HsiaoChenNeural\")\n",
    "    pitch = f\"{tone}Hz\"\n",
    "    rate = f\"{speed}%\"\n",
    "    \n",
    "    output_path = f\"static/{int(time.time() * 1000)}.mp3\"\n",
    "    command = f'edge-tts --text \"{content}\" --write-media \"{output_path}\" --voice \"{voice}\" --pitch=\"{pitch}\" --rate=\"{rate}\"'\n",
    "    success, message = run_command(command)\n",
    "    if success:\n",
    "        return send_file(output_path, mimetype='audio/mpeg')\n",
    "    return jsonify({\"error\": message}), 500\n",
    "# 問答功能\n",
    "def answer_question(question):\n",
    "    inputs = tokenizer(question, return_tensors=\"pt\", padding=True).to(llm_model.device)\n",
    "    outputs = llm_model.generate(inputs['input_ids'], attention_mask=inputs['attention_mask'], max_new_tokens=256, pad_token_id=tokenizer.eos_token_id)\n",
    "    answer = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return converter.convert(answer)\n",
    "# Line handlers\n",
    "@line_handler.add(MessageEvent, message=AudioMessage)\n",
    "def handle_audio_message(event):\n",
    "    audio_path = f'static/{int(time.time())}.mp3'\n",
    "    with open(audio_path, 'wb') as fd:\n",
    "        for chunk in line_bot_api.get_message_content(event.message.id).iter_content():\n",
    "            fd.write(chunk)\n",
    "    text = get_text_from_audio(audio_path)\n",
    "    llm_response = get_response_from_llm(text)\n",
    "    reply_audio_path = get_audio_from_text(llm_response)\n",
    "    if os.path.exists(reply_audio_path):\n",
    "        line_bot_api.reply_message(\n",
    "            event.reply_token,\n",
    "            [\n",
    "                TextSendMessage(text=llm_response),\n",
    "                AudioSendMessage(original_content_url=f'{SERVER_URL}/{reply_audio_path}', duration=330)\n",
    "            ]\n",
    "        )\n",
    "    else:\n",
    "        line_bot_api.reply_message(event.reply_token, TextSendMessage(text=\"合成語音時錯誤，請檢查 TTS Server\"))\n",
    "@line_handler.add(MessageEvent, message=TextMessage)\n",
    "def handle_text_message(event):\n",
    "    text = event.message.text\n",
    "    llm_response = get_response_from_llm(text)\n",
    "    reply_audio_path = get_audio_from_text(llm_response)\n",
    "    if os.path.exists(reply_audio_path):\n",
    "        line_bot_api.reply_message(\n",
    "            event.reply_token,\n",
    "            [\n",
    "                TextSendMessage(text=llm_response),\n",
    "                AudioSendMessage(original_content_url=f'{SERVER_URL}/{reply_audio_path}', duration=330)\n",
    "            ]\n",
    "        )\n",
    "    else:\n",
    "        line_bot_api.reply_message(event.reply_token, TextSendMessage(text=\"合成語音時錯誤，請檢查 TTS Server\"))\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(debug=True, host=\"0.0.0.0\", port=SERVER_PORT, use_reloader=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
